# RUN: docker compose -f docker-compose.prod.yml up -d

services:
  app:
    container_name: per
    image: ${DOCKER_USERNAME}/${DOCKER_APP}:${DOCKER_APP_VERSION}
    restart: unless-stopped

    environment:
      - SPRING_PROFILES_ACTIVE=prod
      - SERVER_PORT=${SERVER_PORT}

      - POSTGRES_URL=${POSTGRES_URL}
      - POSTGRES_USER=${POSTGRES_USER}
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD}

      - REDIS_HOST=${REDIS_HOST}
      - REDIS_PORT=${REDIS_PORT}

      - QDRANT_HOST=${QDRANT_HOST}
      - QDRANT_PORT=${QDRANT_PORT}
      - QDRANT_COLLECTION=${QDRANT_COLLECTION}
      - QDRANT_COLLECTION_PRODUCT=${QDRANT_COLLECTION_PRODUCT}
      - QDRANT_COLLECTION_BRAND=${QDRANT_COLLECTION_BRAND}
      - QDRANT_COLLECTION_CATEGORY=${QDRANT_COLLECTION_CATEGORY}

      - JWT_SECRET=${JWT_SECRET}
      - ACCESS_TOKEN_TTL=${ACCESS_TOKEN_TTL}
      - REFRESH_TOKEN_TTL=${REFRESH_TOKEN_TTL}
      - JWT_ISSUER=${JWT_ISSUER}

      - CLOUDINARY_CLOUD_NAME=${CLOUDINARY_CLOUD_NAME}
      - CLOUDINARY_API_KEY=${CLOUDINARY_API_KEY}
      - CLOUDINARY_API_SECRET=${CLOUDINARY_API_SECRET}
      - CLOUDINARY_FOLDER=${CLOUDINARY_FOLDER}

      - MAIL_USERNAME=${MAIL_USERNAME}
      - MAIL_PASSWORD=${MAIL_PASSWORD}
      - MAIL_FROM=${MAIL_FROM}

      - CORS_ALLOWED_ORIGINS=${CORS_ALLOWED_ORIGINS}
      - APP_BASE_URL=${APP_BASE_URL}

      - PAY_OS_CLIENT_ID=${PAY_OS_CLIENT_ID}
      - PAY_OS_API_KEY=${PAY_OS_API_KEY}
      - PAY_OS_CHECKSUM_KEY=${PAY_OS_CHECKSUM_KEY}

      - KAFKA_BOOTSTRAP_SERVERS=kafka:9092
      - LOGSTASH_HOST=logstash
      - ELASTICSEARCH_URI=${ELASTICSEARCH_URI}
      - APP_ELASTICSEARCH_AUTO_REINDEX=${APP_ELASTICSEARCH_AUTO_REINDEX}

      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - OPENAI_CHAT_MODEL=${OPENAI_CHAT_MODEL:-gpt-3.5-turbo}
      - OPENAI_EMBEDDING_MODEL=${OPENAI_EMBEDDING_MODEL:-text-embedding-3-small}
      - RAG_SEARCH_TOP_K=${RAG_SEARCH_TOP_K:-5}
      - RAG_SIMILARITY_THRESHOLD=${RAG_SIMILARITY_THRESHOLD:-0.3}

      - APP_ADMIN_USERNAME=${APP_ADMIN_USERNAME}
      - APP_ADMIN_EMAIL=${APP_ADMIN_EMAIL}
      - APP_ADMIN_PASSWORD=${APP_ADMIN_PASSWORD}
    volumes:
      - ./knowledge:/app/knowledge:ro

    ports:
      - "8080:8080"
    networks:
      - per-network
    depends_on:
      - db
      - redis
      - elasticsearch

  db:
    image: pgvector/pgvector:pg16
    container_name: postgres
    restart: unless-stopped
    environment:
      POSTGRES_DB: ${POSTGRES_DB}
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
    command:
      - "postgres"
      - "-c"
      - "wal_level=logical"
      - "-c"
      - "max_wal_senders=4"
      - "-c"
      - "max_replication_slots=4"
    ports: [ "127.0.0.1:5432:5432" ]
    networks:
      - per-network
    volumes: [ "db:/var/lib/postgresql/data" ]
    healthcheck:
      test: [ "CMD-SHELL", "pg_isready -U $${POSTGRES_USER} -d $${POSTGRES_DB}" ]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 30s

  redis:
    image: redis:7-alpine
    container_name: redis
    restart: unless-stopped
    ports:
      - "127.0.0.1:6379:6379"
    networks:
      - per-network

  kafka:
    image: confluentinc/cp-kafka:7.6.1
    container_name: kafka
    ports:
      - "127.0.0.1:29092:29092"
    networks:
      - per-network
    environment:
      # KRaft mode settings
      KAFKA_NODE_ID: 1
      KAFKA_PROCESS_ROLES: broker,controller
      KAFKA_CONTROLLER_QUORUM_VOTERS: 1@kafka:9093
      KAFKA_LISTENERS: PLAINTEXT://kafka:9092,CONTROLLER://kafka:9093,PLAINTEXT_HOST://0.0.0.0:29092
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092,PLAINTEXT_HOST://localhost:29092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,CONTROLLER:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_CONTROLLER_LISTENER_NAMES: CONTROLLER
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      CLUSTER_ID: 'MkU3OEVBNTcwNTJENDM2Qg'
      KAFKA_LOG_DIRS: /var/lib/kafka/data
    volumes:
      - kafka_data:/var/lib/kafka/data
    healthcheck:
      test: [ "CMD-SHELL", "kafka-broker-api-versions --bootstrap-server localhost:9092 || exit 1" ]
      interval: 15s
      timeout: 10s
      retries: 5
      start_period: 60s
    deploy:
      resources:
        limits:
          memory: 1G

  kafka-ui:
    container_name: kafka-ui
    image: provectuslabs/kafka-ui:latest
    ports:
      - "127.0.0.1:8090:8080"
    networks:
      - per-network
    environment:
      DYNAMIC_CONFIG_ENABLED: "true"
      KAFKA_CLUSTERS_0_NAME: local
      KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS: kafka:9092
      AUTH_TYPE: LOGIN_FORM
      SPRING_SECURITY_USER_NAME: ${KAFKA_UI_USERNAME}
      SPRING_SECURITY_USER_PASSWORD: ${KAFKA_UI_PASSWORD}

  debezium-kafka-connect:
    image: debezium/connect:2.5
    container_name: debezium-kafka-connect
    ports:
      - "127.0.0.1:8083:8083"
    networks:
      - per-network
    environment:
      BOOTSTRAP_SERVERS: kafka:9092
      GROUP_ID: debezium-connect
      CONFIG_STORAGE_TOPIC: debezium_connect_configs
      OFFSET_STORAGE_TOPIC: debezium_connect_offsets
      STATUS_STORAGE_TOPIC: debezium_connect_statuses
      CONFIG_STORAGE_REPLICATION_FACTOR: 1
      OFFSET_STORAGE_REPLICATION_FACTOR: 1
      STATUS_STORAGE_REPLICATION_FACTOR: 1
      KEY_CONVERTER: org.apache.kafka.connect.json.JsonConverter
      VALUE_CONVERTER: org.apache.kafka.connect.json.JsonConverter
      KEY_CONVERTER_SCHEMAS_ENABLE: "false"
      VALUE_CONVERTER_SCHEMAS_ENABLE: "false"
    depends_on:
      - kafka
      - db
    healthcheck:
      test: [ "CMD", "curl", "-f", "http://localhost:8083/connectors" ]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 60s

  debezium-ui:
    image: debezium/debezium-ui:2.5
    container_name: debezium-ui
    ports:
      - "127.0.0.1:8084:8080"
    networks:
      - per-network
    environment:
      KAFKA_CONNECT_URIS: http://debezium-kafka-connect:8083
    depends_on:
      - debezium-kafka-connect

  init-kafka-connect:
    build:
      context: ./debezium
    image: per-init-connector:latest
    container_name: init-kafka-connect
    networks:
      - per-network
    environment:
      KAFKA_CONNECT_URL: http://debezium-kafka-connect:8083
      CONNECTOR_CONFIG: /config/connector-postgres.json
      MAX_RETRIES: 60
      RETRY_INTERVAL: 5
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_DB: ${POSTGRES_DB}

    depends_on:
      debezium-kafka-connect:
        condition: service_healthy
    restart: "no"

  prometheus:
    image: prom/prometheus:latest
    container_name: prometheus
    user: root
    restart: unless-stopped
    volumes:
      - ./monitor/prometheus.prod.yml:/etc/prometheus/prometheus.yml
      - ./data/prometheus_data:/prometheus
    command:
      - "--config.file=/etc/prometheus/prometheus.yml"
      - "--storage.tsdb.path=/prometheus"
      - "--web.console.libraries=/etc/prometheus/console_libraries"
      - "--web.console.templates=/etc/prometheus/consoles"
      - "--web.enable-lifecycle"
    ports:
      - "127.0.0.1:9091:9090"
    networks:
      - per-network

  grafana:
    image: grafana/grafana
    container_name: grafana
    user: root
    hostname: grafana
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=admin
      - GF_USERS_ALLOW_SING_UP=false
      - GF_SERVER_DOMAIN=localhost
      - GF_LOG_MODE=console file
      - GF_LOG_FILTERS=alerting.notifier.slack:debug alertmanager:debug ngalert:debug
    volumes:
      - ./grafana-storage:/var/lib/grafana
    ports:
      - "127.0.0.1:3000:3000"
    networks:
      - per-network

  node-exporter:
    image: prom/node-exporter:latest
    container_name: node-exporter
    restart: unless-stopped
    volumes:
      - /proc:/host/proc:ro
      - /sys:/host/sys:ro
      - /:/rootfs:ro
    command:
      - --path.procfs=/host/proc
      - --path.rootfs=/rootfs
      - --path.sysfs=/host/sys
      - --collector.filesystem.mount-points-exclude=^/(sys|proc|dev|host|etc)(5690|/)
    ports:
      - "127.0.0.1:9100:9100"
    networks:
      - per-network

  redis-exporter:
    image: oliver006/redis_exporter
    container_name: redis-exporter
    command: -redis.addr redis://redis:6379
    ports:
      - "127.0.0.1:9121:9121"
    networks:
      - per-network

  postgres_exporter:
    image: prometheuscommunity/postgres-exporter
    container_name: postgres-exporter
    environment:
      DATA_SOURCE_URI: "postgres:5432/postgres?sslmode=disable"
      DATA_SOURCE_USER: ${POSTGRES_USER}
      DATA_SOURCE_PASS: ${POSTGRES_PASSWORD}
    networks:
      - per-network
    ports:
      - "127.0.0.1:9187:9187"

  elasticsearch:
    image: elasticsearch:7.17.25
    container_name: elasticsearch
    volumes:
      - ./elk/elasticsearch.yml:/usr/share/elasticsearch/config/elasticsearch.yml
    ports:
      - "127.0.0.1:200:9200"
      - "127.0.0.1:9300:9300"
    environment:
      - ES_JAVA_OPTS=-Xmx256m -Xms256m
      - discovery.type=single-node
    networks:
      - per-network
    healthcheck:
      test: [ "CMD-SHELL", "curl -sf http://localhost:9200/_cluster/health || exit 1" ]
      interval: 15s
      timeout: 10s
      retries: 5
      start_period: 60s
    deploy:
      resources:
        limits:
          memory: 2G

  logstash:
    image: logstash:7.17.25
    container_name: logstash
    volumes:
      - ./elk/logstash.yml:/usr/share/logstash/config/logstash.yml
      - ./elk/pipeline:/usr/share/logstash/pipeline
    ports:
      - "127.0.0.1:5044:5044"
      - "127.0.0.1:5033:5000/tcp"
      - "127.0.0.1:5022:5000/udp"
      - "127.0.0.1:9600:9600"
    environment:
      LS_JAVA_OPTS: "-Xmx256m -Xms256m"
    networks:
      - per-network
    depends_on:
      - elasticsearch

  kibana:
    image: kibana:7.17.25
    container_name: kibana
    volumes:
      - ./elk/kibana.yml:/usr/share/kibana/config/kibana.yml
    ports:
      - "127.0.0.1:5601:5601"
    networks:
      - per-network
    depends_on:
      - elasticsearch

  qdrant:
    image: qdrant/qdrant:latest
    container_name: qdrant
    restart: unless-stopped
    ports:
      - "127.0.0.1:6333:6333"
      - "127.0.0.1:6334:6334"
    volumes:
      - ./qdrant-storage:/qdrant/storage
    networks:
      - per-network

volumes:
  db:
  kafka_data:


networks:
  per-network:
    driver: bridge
